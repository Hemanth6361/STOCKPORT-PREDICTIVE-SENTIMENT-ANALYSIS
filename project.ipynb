{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:38.458041Z",
     "iopub.status.busy": "2022-08-29T10:11:38.457138Z",
     "iopub.status.idle": "2022-08-29T10:11:46.804962Z",
     "shell.execute_reply": "2022-08-29T10:11:46.803745Z",
     "shell.execute_reply.started": "2022-08-29T10:11:38.457918Z"
    },
    "id": "uRPcgt0DuYIM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Conv1D,Conv2D,MaxPooling2D,MaxPooling1D,Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "# from keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import seaborn as sns\n",
    "#from datetime import datetime\n",
    "\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM,Bidirectional\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpA65SL-uYIV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:46.808566Z",
     "iopub.status.busy": "2022-08-29T10:11:46.807497Z",
     "iopub.status.idle": "2022-08-29T10:11:46.866566Z",
     "shell.execute_reply": "2022-08-29T10:11:46.865695Z",
     "shell.execute_reply.started": "2022-08-29T10:11:46.808517Z"
    },
    "id": "ncsYmfaEuYIV",
    "outputId": "27202b93-00be-4891-9b67-a2f1b9704664",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Read the csv file\n",
    "df = pd.read_csv('Final_nflx_data_2018-2022.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20dF1gi2RACZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Understanding the time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:46.868304Z",
     "iopub.status.busy": "2022-08-29T10:11:46.867811Z",
     "iopub.status.idle": "2022-08-29T10:11:47.477349Z",
     "shell.execute_reply": "2022-08-29T10:11:47.476484Z",
     "shell.execute_reply.started": "2022-08-29T10:11:46.868273Z"
    },
    "id": "C-ChtLPrQ8Uq",
    "outputId": "0d355965-434a-4d29-fc8d-c6b5f3a6e582",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(25,7));\n",
    "sns.lineplot(x=df[\"date\"],y=df[\"Adj Close\"])\n",
    "df['sentiment_analysis']=df['P_mean']\n",
    "df['sentiment_analysis']=df['sentiment_analysis'].apply(lambda x: 'pos' if x>0 else 'nue' if x==0 else 'neg')\n",
    "sns.scatterplot(x=df[\"date\"],y=df['Adj Close'],hue=df['sentiment_analysis'],palette=['y','r','g'])\n",
    "plt.xticks(rotation=45);\n",
    "plt.title(\"Stock market of Netfilx from Jan-2018 to Jul-2022\",fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.480071Z",
     "iopub.status.busy": "2022-08-29T10:11:47.479745Z",
     "iopub.status.idle": "2022-08-29T10:11:47.488554Z",
     "shell.execute_reply": "2022-08-29T10:11:47.487719Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.480041Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['sentiment_analysis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.490734Z",
     "iopub.status.busy": "2022-08-29T10:11:47.489956Z",
     "iopub.status.idle": "2022-08-29T10:11:47.517932Z",
     "shell.execute_reply": "2022-08-29T10:11:47.516552Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.490699Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=df.drop(list(range(14)),axis=0,inplace=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.5204Z",
     "iopub.status.busy": "2022-08-29T10:11:47.519764Z",
     "iopub.status.idle": "2022-08-29T10:11:47.548814Z",
     "shell.execute_reply": "2022-08-29T10:11:47.547794Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.520354Z"
    },
    "id": "K6ySZfDhNqhx",
    "outputId": "397a73ba-290b-48c5-da91-1490edf627e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dates = pd.to_datetime(df['date'])\n",
    "# print(train_dates.tail(15)) #Check last few dates.\n",
    "\n",
    "#Variables for training\n",
    "cols = [\n",
    "    'Open',\n",
    "    'High', 'Low',\n",
    "    'Close',\n",
    "    'Volume',\n",
    "    'Adj Close',\n",
    "    'P_mean',\n",
    "        ]\n",
    "#Date and volume columns are not used in training.\n",
    "print(cols)\n",
    "\n",
    "#New dataframe with only training data - 5 columns\n",
    "df_for_training = df[cols].astype(float)\n",
    "df_for_training.index=df['date']\n",
    "df_for_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data scaling for LSTM because uses sigmoid and tanh that are sensitive to magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.550728Z",
     "iopub.status.busy": "2022-08-29T10:11:47.55025Z",
     "iopub.status.idle": "2022-08-29T10:11:47.567341Z",
     "shell.execute_reply": "2022-08-29T10:11:47.566519Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.550683Z"
    },
    "id": "KzyZJLm1uYIW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training)\n",
    "\n",
    "scaler_for_inference = MinMaxScaler()\n",
    "scaler_for_inference.fit_transform(df_for_training.loc[:,['Open','Adj Close']])\n",
    "\n",
    "df_for_training_scaled\n",
    "# df_for_training_scaled=df_for_training.copy()\n",
    "# df_for_training_scaled=df_for_training_scaled.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7ZZZH9suYIX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.569591Z",
     "iopub.status.busy": "2022-08-29T10:11:47.568922Z",
     "iopub.status.idle": "2022-08-29T10:11:47.589253Z",
     "shell.execute_reply": "2022-08-29T10:11:47.58845Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.569558Z"
    },
    "id": "fcM2mi7euYIX",
    "outputId": "03308aa4-0796-4e66-daf3-23a5f76fe230",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Empty lists to be populated using formatted training data\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 5  # Number of past days we want to use to predict the future.\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#In my example, my df_for_training_scaled has a shape (12823, 5)\n",
    "#12823 refers to the number of data points and 5 refers to the columns (multi-variables).\n",
    "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future,[0,-2]])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "print('TrainX shape = {}.'.format(trainX.shape))\n",
    "print('TrainY shape = {}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train test split for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.591506Z",
     "iopub.status.busy": "2022-08-29T10:11:47.590866Z",
     "iopub.status.idle": "2022-08-29T10:11:47.657802Z",
     "shell.execute_reply": "2022-08-29T10:11:47.656498Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.591448Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_lstm_without_twitter, X_test_lstm_without_twitter, y_train_lstm_without_twitter, y_test_lstm_without_twitter = train_test_split(trainX[:,:,:-1], trainY, test_size=0.2, shuffle=False)\n",
    "\n",
    "X_train_lstm_twitter, X_test_lstm_twitter, y_train_lstm_twitter, y_test_lstm_twitter = train_test_split(trainX, trainY, test_size=0.2, shuffle=False)\n",
    "\n",
    "X_train_lstm_without_twitter.shape,X_train_lstm_twitter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train validation split for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.663649Z",
     "iopub.status.busy": "2022-08-29T10:11:47.662883Z",
     "iopub.status.idle": "2022-08-29T10:11:47.673259Z",
     "shell.execute_reply": "2022-08-29T10:11:47.672532Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.663603Z"
    },
    "id": "k2RUQj94uYIY",
    "outputId": "87d72b5c-b632-4053-99a4-7e1efd63dbbb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_lstm_without_twitter, X_val_lstm_without_twitter, y_train_lstm_without_twitter, y_val_lstm_without_twitter = train_test_split(X_train_lstm_without_twitter, y_train_lstm_without_twitter, test_size=0.1, shuffle=False)\n",
    "\n",
    "X_train_lstm_twitter, X_val_lstm_twitter, y_train_lstm_twitter, y_val_lstm_twitter = train_test_split(X_train_lstm_twitter, y_train_lstm_twitter, test_size=0.1, shuffle=False)\n",
    "\n",
    "X_train_lstm_without_twitter.shape,X_train_lstm_twitter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.67501Z",
     "iopub.status.busy": "2022-08-29T10:11:47.674537Z",
     "iopub.status.idle": "2022-08-29T10:11:47.687824Z",
     "shell.execute_reply": "2022-08-29T10:11:47.686853Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.674981Z"
    },
    "id": "2eX63nBDuYIZ",
    "outputId": "97a66021-0be3-4d2e-cf51-eed96cabb5c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    tf.random.set_seed(seed)\n",
    "    cnn_lstm_model = Sequential()\n",
    "\n",
    "    cnn_lstm_model.add(Conv1D(filters=128, kernel_size=2, strides=1, padding='valid', input_shape=input_shape))\n",
    "    cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    cnn_lstm_model.add(Conv1D(filters=64, kernel_size=2, strides=1, padding='valid'))\n",
    "    cnn_lstm_model.add(MaxPooling1D(pool_size=1, strides=2))\n",
    "    # cnn_lstm_model.add(MaxPooling1D(pool_size=1, strides=2))\n",
    "\n",
    "    cnn_lstm_model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "    cnn_lstm_model.add(Dropout(0.2))\n",
    "    cnn_lstm_model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "    cnn_lstm_model.add(Dropout(0.2))\n",
    "\n",
    "    cnn_lstm_model.add(Dense(32, activation='relu'))\n",
    "\n",
    "\n",
    "    cnn_lstm_model.add(Dense(trainY.shape[2], activation='relu'))\n",
    "\n",
    "    # cnn_lstm_model.build(input_shape=(trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "\n",
    "    cnn_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "    cnn_lstm_model.summary()\n",
    "    return cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:11:47.689384Z",
     "iopub.status.busy": "2022-08-29T10:11:47.689057Z",
     "iopub.status.idle": "2022-08-29T10:12:55.052508Z",
     "shell.execute_reply": "2022-08-29T10:12:55.051452Z",
     "shell.execute_reply.started": "2022-08-29T10:11:47.689354Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "cnn_lstm_model_without_twitter=build_model((X_train_lstm_without_twitter.shape[1],X_train_lstm_without_twitter.shape[2]))\n",
    "cnn_lstm_model_twitter=build_model((X_train_lstm_twitter.shape[1],X_train_lstm_twitter.shape[2]))\n",
    "\n",
    "history_without_twitter = cnn_lstm_model_without_twitter.fit(X_train_lstm_without_twitter, y_train_lstm_without_twitter, epochs=50, batch_size=64, validation_data=(X_val_lstm_without_twitter, y_val_lstm_without_twitter), verbose=1, )\n",
    "\n",
    "\n",
    "history_twitter = cnn_lstm_model_twitter.fit(X_train_lstm_twitter, y_train_lstm_twitter, epochs=50, batch_size=64, validation_data=(X_val_lstm_twitter, y_val_lstm_twitter), verbose=1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting Training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:12:55.054385Z",
     "iopub.status.busy": "2022-08-29T10:12:55.054072Z",
     "iopub.status.idle": "2022-08-29T10:12:55.316305Z",
     "shell.execute_reply": "2022-08-29T10:12:55.315149Z",
     "shell.execute_reply.started": "2022-08-29T10:12:55.054357Z"
    },
    "id": "cBz6KkBFuYIZ",
    "outputId": "21e0da3c-fcea-4eb1-9dac-01d4267a4c9a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(history_without_twitter.history['loss'], label='Training loss')\n",
    "plt.plot(history_without_twitter.history['val_loss'], label='Validation loss')\n",
    "plt.title('Training loss Vs. Validation loss without twitter sentiment analysis')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:12:55.318839Z",
     "iopub.status.busy": "2022-08-29T10:12:55.31784Z",
     "iopub.status.idle": "2022-08-29T10:12:55.511355Z",
     "shell.execute_reply": "2022-08-29T10:12:55.510002Z",
     "shell.execute_reply.started": "2022-08-29T10:12:55.318805Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(history_twitter.history['loss'], label='Training loss')\n",
    "plt.plot(history_twitter.history['val_loss'], label='Validation loss')\n",
    "plt.title('Training loss Vs. Validation loss including twitter sentiment analysis')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:12:55.513744Z",
     "iopub.status.busy": "2022-08-29T10:12:55.513257Z",
     "iopub.status.idle": "2022-08-29T10:12:55.523953Z",
     "shell.execute_reply": "2022-08-29T10:12:55.522825Z",
     "shell.execute_reply.started": "2022-08-29T10:12:55.513699Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "def plot_predictions_with_dates (type,twitter,dates,y_actual_lstm,y_pred_lstm):\n",
    "    predicted_features=['Open','Adj Close']\n",
    "    for i,predicted_feature in enumerate(predicted_features):\n",
    "        plt.figure(figsize=(15,6))\n",
    "        if twitter :\n",
    "            plt.title(f'LSTM {type} prediction of {predicted_feature} feature After adding twitter sentiment analysis')\n",
    "        else:\n",
    "            plt.title(f'LSTM {type} prediction of {predicted_feature} feature without twitter sentiment analysis')\n",
    "        sns.lineplot(x=dates, y=y_actual_lstm[:,i],label='Actual')\n",
    "        sns.lineplot(x=dates, y=y_pred_lstm[:, i], label='Predicted')\n",
    "        plt.show()\n",
    "        error=mean_squared_error(y_actual_lstm[:,i], y_pred_lstm[:, i])\n",
    "        print(f'Mean square error for {predicted_feature} ={error}')\n",
    "    print('Total mean square error', mean_squared_error(y_actual_lstm, y_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Computing training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:12:55.526033Z",
     "iopub.status.busy": "2022-08-29T10:12:55.525665Z",
     "iopub.status.idle": "2022-08-29T10:12:59.417616Z",
     "shell.execute_reply": "2022-08-29T10:12:59.416377Z",
     "shell.execute_reply.started": "2022-08-29T10:12:55.526001Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_dates= df_for_training.index[:X_train_lstm_without_twitter.shape[0]]\n",
    "#Make prediction\n",
    "training_prediction_without_twitter = cnn_lstm_model_without_twitter.predict(X_train_lstm_without_twitter)\n",
    "\n",
    "training_prediction_twitter = cnn_lstm_model_twitter.predict(X_train_lstm_twitter)\n",
    "\n",
    "training_prediction_without_twitter=training_prediction_without_twitter.reshape(training_prediction_without_twitter.shape[0], training_prediction_without_twitter.shape[2])\n",
    "\n",
    "training_prediction_twitter=training_prediction_twitter.reshape(training_prediction_twitter.shape[0], training_prediction_twitter.shape[2])\n",
    "\n",
    "y_train_pred_lstm_without_twitter = scaler_for_inference.inverse_transform(training_prediction_without_twitter)\n",
    "\n",
    "y_train_pred_lstm_twitter = scaler_for_inference.inverse_transform(training_prediction_twitter)\n",
    "\n",
    "y_train_lstm_reshaped_without_twitter=y_train_lstm_without_twitter.reshape(y_train_lstm_without_twitter.shape[0], y_train_lstm_without_twitter.shape[2])\n",
    "\n",
    "y_train_actual_lstm = scaler_for_inference.inverse_transform(y_train_lstm_reshaped_without_twitter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "####  Training accuracy without twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T10:12:59.419502Z",
     "iopub.status.busy": "2022-08-29T10:12:59.419133Z",
     "iopub.status.idle": "2022-08-29T10:13:00.125049Z",
     "shell.execute_reply": "2022-08-29T10:13:00.123812Z",
     "shell.execute_reply.started": "2022-08-29T10:12:59.419451Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_predictions_with_dates('Training',False,training_dates,y_train_actual_lstm,y_train_pred_lstm_without_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cece6f5d199374f061c23567806751a68b024e7b4429bb31c4521998b2c52138"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
